num_epochs: 8
batch_size: 16
lr: 6.0e-05
cuda: 0
output_dir: ./runs/para_train_t5/_stage2/aesop_triplet_full_finetune_3
model: ./curriculum_pre_training/runs/syntax_seed_test/0_8_data/checkpoints/model/
tokenizer: ./pretrained-models/syntax-t5-base-node-with-NT/
model_type: t5
max_length: 256
use_checkpoint: null
num_warmup_epochs: 0
cosine_multiplier: 1.2
target_only: false
use_tgt_as_ref: false
use_num_postfix: false
instance_format_name: aesop_nooutputtree
test_only: false
data: ParaNMT50m_triple
use_opti: false
subset: false
gradient_accumulation_steps: 8
num_workers: 5
prefetch_factor: 2
prune_height: 5
skip_post_process: false
find_lr: false
decide_generation_kwargs: false
